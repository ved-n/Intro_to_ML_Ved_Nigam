# Intro to Machine Learning Portfolio
### Ved Nigam

## Component 0
<li class="masthead__menu-item">
          <a href="https://github.com/ved-n/4375_Ved_Nigam_Work/blob/main/Overview%20of%20ML.pdf">Overview of ML</a>
        </li>
        
In this assignment, we researched what Machine Learning is and how it has developed recently. It seems very daunting as a term and concept; but with more research, it all seems more doable. This document is my initial research/findings of what Machine Learning is.

## Component 1
<li class="masthead__menu-item">
          <a href="https://github.com/ved-n/4375_Ved_Nigam_Work/tree/main/Exploration_cpp">Data Exploration in C++</a>
        </li>
        
Our first assignment in C++ to refresh some basic concepts we learned in earlier courses. This code reads in data from a 'Boston.csv' file which contains housing market data of a certain time period in Boston. We perform simple statistical analysis (mean, median, sum, range) as well as some intermediate statistical analysis (covariance and correlation). This was a very nice intro to what we will continue to work on throughout this class. 
        
## Component 2
<li class="masthead__menu-item">
          <a href="https://github.com/ved-n/4375_Ved_Nigam_Work/tree/main/Regression.pdf">Linear Regression on a CPU-FPS Dataset</a>
        </li>
        
## Component 3
A Linear Regression model trained in R on A CPU dataset. The model aims to find a relationship between the performance metrics of a CPU and how many Frames per Second it is able to support.
<li class="masthead__menu-item">
          <a href="https://github.com/ved-n/4375_Ved_Nigam_Work/tree/main/classification.pdf">Logistic Regression on a Diamond Dataset</a>
        </li>
      
## Component 4
<li class="masthead__menu-item">
          <a href="https://github.com/ved-n/4375_Ved_Nigam_Work/tree/main/LinReg and NB from Scratch.pdf">Document of Analysis of LinReg and NB from Scratch in C++</a>
        </li>

## Component 5
<li class="masthead__menu-item">
          <a href="https://github.com/ved-n/4375_Ved_Nigam_Work/tree/main/linear_regression.cpp">Linear Regression Algorithm in C++</a>
        </li>

<li class="masthead__menu-item">
          <a href="https://github.com/ved-n/4375_Ved_Nigam_Work/tree/main/naive_bayes_from_scratch.cpp">Incomplete Naive Bayes Algorithm in C++</a>
        </li>

## Component 6
The following few documents are part of a group project. I was the one who split up the work, set up the calls, peer evaluation, and corresponded with the group as needed. The narrative towards the end is also written by me, which is a good sumamry of the concepts that were experimented with in this Similariy and Ensemble project.

<li class="masthead__menu-item">
          <a href="https://github.com/ved-n/4375_Ved_Nigam_Work/tree/main/SFSRegression.pdf">Regression with kNN and Decision Trees in R</a>
        </li>
This is a Linear Regression using the K-Nearest-Neighbor algorithm and Decision trees. kNN is optimal for regression and Decision Trees are very visually appealing for classification on a dataset. 

<li class="masthead__menu-item">
          <a href="https://github.com/ved-n/4375_Ved_Nigam_Work/tree/main/classification.pdf">Classification with kNN and Decision Trees in R</a>
        </li>
This continues on the project by using kNN and Decision trees with the goal of classification instead of regression.

<li class="masthead__menu-item">
          <a href="https://github.com/ved-n/4375_Ved_Nigam_Work/tree/main/Clustering.pdf">kMeans and Hierarchal Clustering in R</a>
        </li>
This is an introduction to clustering of a dataset. It uses kMeans and Hierarchal clustering. This is not a classification algorithm, but it is a way to make data more interpretable by clustering similar datapoints.

<li class="masthead__menu-item">
          <a href="https://github.com/ved-n/4375_Ved_Nigam_Work/tree/main/PCA_and_LDA.pdf">Changing Dimensions of data with PCA and LDA</a>
        </li>
Experimented with changing the dimensions of data. The main difference between this and clustering is that this simply changes the dimensions of the data by normalizing the data.

<li class="masthead__menu-item">
          <a href="https://github.com/ved-n/4375_Ved_Nigam_Work/tree/main/Searching For Similarity Narrative.pdf">Narrative on kMeans, Decision Trees, Clustering, and Data Dimensionality</a>
        </li>
A summary of the concepts that were implemented above in this component of the portfolio.        

## Component 7
<li class="masthead__menu-item">
          <a href="https://github.com/ved-n/4375_Ved_Nigam_Work/tree/main/PythonMLwSklearn.pdf">Intro to ML in Python</a>
        </li>
A pivot from R to Python for Machine Learning. We introduced the most popular libraries such as Numpy, Pandas, Seaborn, and SKLearn for data science.

## Component 8
<li class="masthead__menu-item">
          <a href="https://github.com/ved-n/4375_Ved_Nigam_Work/blob/main/ImageClassification.pdf">Image Classification using Sequential and CNN</a>
        </li>
Our final component of this portfolio, writted in Python. My project was classifying an image dataset of balls. There are about 20-25 classes that the model could have sorted it into. I used a Sequential model and a CNN model, getting better accuracy on the model with the Sequential model. The Tensorflow website tutorial for Keras image classification was extremely helpful with this component.

## Final thoughts on the portfolio
This Intro to Machine Learning class at the University of Texas at Dallas with Dr. Karen Mazidi has been one of the most engaging courses I have taken academically. I was introduced to so many topics and this is has given me significant motivation to pursue a professional career in the Data Science/Machine Learning industry. I will be interning as a Technology InStep Intern with Infosys this Summer of 2023, and I am extremely excited to use the knowledge I have gained in this course. I do not have any plans for future projects, but I do hope to continue learning more about Tensorflow as it is becoming more prevalant in all industries.
